

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Chris·Yougn">
  <meta name="keywords" content="">
  
    <meta name="description" content="1.卷积运算与卷积层说卷积层，我们得先从卷积运算开始，卷积运算就是卷积核在输入信号（图像）上滑动， 相应位置上进行「乘加」。卷积核又称为滤过器，过滤器，可认为是某种模式，某种特征。 卷积过程类似于用一个模板去图像上寻找与它相似的区域， 与卷积核模式越相似， 激活值越高， 从而实现特征提取。好吧，估计依然懵逼，下面我们就看看 1d、2d、3d的卷积示意图，通过动图的方式看看卷积操作到底在干啥？ 1">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning—Layer说明">
<meta property="og:url" content="http://example.com/2022/07/01/DeepLearning/%E5%90%84%E4%B8%AA%E5%B1%82%E7%9A%84%E8%A7%A3%E9%87%8A/index.html">
<meta property="og:site_name" content="相阳的小屋">
<meta property="og:description" content="1.卷积运算与卷积层说卷积层，我们得先从卷积运算开始，卷积运算就是卷积核在输入信号（图像）上滑动， 相应位置上进行「乘加」。卷积核又称为滤过器，过滤器，可认为是某种模式，某种特征。 卷积过程类似于用一个模板去图像上寻找与它相似的区域， 与卷积核模式越相似， 激活值越高， 从而实现特征提取。好吧，估计依然懵逼，下面我们就看看 1d、2d、3d的卷积示意图，通过动图的方式看看卷积操作到底在干啥？ 1">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/src/640-165691974012416.png">
<meta property="og:image" content="http://example.com/src/640-16464011129871-165691974235919.gif">
<meta property="og:image" content="http://example.com/src/640-16464011129872-165691974500122.gif">
<meta property="og:image" content="http://example.com/src/640-16464011129893-165691975338925.gif">
<meta property="og:image" content="http://example.com/src/640-16464011129894-165691975764428.png">
<meta property="og:image" content="http://example.com/src/640-16464011129895-165691976075031.gif">
<meta property="og:image" content="http://example.com/src/640-16464011129896-165691976230334.gif">
<meta property="og:image" content="http://example.com/src/640-16464011129897-165691976455037.gif">
<meta property="og:image" content="http://example.com/src/640-16464011129898-165691976638840.png">
<meta property="og:image" content="http://example.com/src/640-16464011129909-165691977038443.png">
<meta property="og:image" content="http://example.com/src/640-164640111299010-165691977227646.png">
<meta property="og:image" content="http://example.com/src/640-164640111299011-165691977391849.png">
<meta property="og:image" content="f:/notes/深度学习/src/640-164640111299012.png">
<meta property="og:image" content="f:/notes/深度学习/src/640-164640111299013.gif">
<meta property="og:image" content="http://example.com/src/640-164640111299014-165691977665652.gif">
<meta property="og:image" content="http://example.com/src/640-164640111299015-165691978158855.gif">
<meta property="og:image" content="http://example.com/src/640-164640111299016-165691978313158.png">
<meta property="og:image" content="http://example.com/src/640-164640111299117-165691981478961.gif">
<meta property="og:image" content="http://example.com/src/640-164640111299118-165691981878464.png">
<meta property="og:image" content="http://example.com/src/640-164640111299119-165691982268167.png">
<meta property="og:image" content="http://example.com/src/640-164640111299120-165691982723470.gif">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299121.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299122.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299123.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299124.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299125.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299126.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299127.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299228.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299229.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299230.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299231.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299232.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299233.png">
<meta property="og:image" content="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299234.png">
<meta property="article:published_time" content="2022-06-30T16:00:00.000Z">
<meta property="article:modified_time" content="2022-08-01T02:24:48.142Z">
<meta property="article:author" content="Chris·Yougn">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/src/640-165691974012416.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Deep Learning—Layer说明 - 相阳的小屋</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.1","typing":{"enable":true,"typeSpeed":60,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":false,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":null,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Chris Yougn的小屋</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Deep Learning—Layer说明"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-07-01 00:00" pubdate>
          2022年7月1日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          47 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Deep Learning—Layer说明</h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：2022年8月1日 上午
                  
                
              </p>
            
            <div class="markdown-body">
              
              <p><img src="/src/640-165691974012416.png" alt="图片"></p>
<h1 id="1-卷积运算与卷积层"><a href="#1-卷积运算与卷积层" class="headerlink" title="1.卷积运算与卷积层"></a>1.卷积运算与卷积层</h1><p>说卷积层，我们得先从卷积运算开始，卷积运算就是卷积核在输入信号（图像）上滑动， 相应位置上进行<strong>「乘加」</strong>。卷积核又称为滤过器，过滤器，可认为是某种模式，某种特征。</p>
<p>卷积过程类似于用一个模板去图像上寻找与它相似的区域， 与卷积核模式越相似， 激活值越高， 从而实现特征提取。好吧，估计依然懵逼，下面我们就看看 1d、2d、3d的卷积示意图，通过动图的方式看看卷积操作到底在干啥？</p>
<h2 id="1-1-1d-2d-3d-卷积示意"><a href="#1-1-1d-2d-3d-卷积示意" class="headerlink" title="1.1 1d 2d 3d 卷积示意"></a>1.1 1d 2d 3d 卷积示意</h2><p>一般情况下，卷积核在几个维度上滑动，就是几维卷积。下面再看几张动图感受一下不同维度的卷积操作，注意下面都是一个卷积核：</p>
<p>一维卷积示意</p>
<p><img src="/src/640-16464011129871-165691974235919.gif" alt="图片"></p>
<p>二维卷积示意</p>
<p><img src="/src/640-16464011129872-165691974500122.gif" alt="图片"></p>
<p>三维卷积示意</p>
<p><img src="/src/640-16464011129893-165691975338925.gif" alt="图片"></p>
<h2 id="1-2-nn-Conv2d"><a href="#1-2-nn-Conv2d" class="headerlink" title="1.2 nn.Conv2d"></a>1.2 nn.Conv2d</h2><p><code>nn.Conv2d</code>: 对多个二维信号进行二维卷积</p>
<p><img src="/src/640-16464011129894-165691975764428.png" alt="图片"></p>
<p>主要参数：</p>
<ul>
<li>in_channels: 输入通道数</li>
<li>out_channels: 输出通道数， 等价于卷积核个数</li>
<li>kernel_size: 卷积核尺寸， 这个代表着卷积核的大小</li>
<li>stride: 步长， 这个指的卷积核滑动的时候，每一次滑动几个像素。下面看个动图来理解步长的概念：左边那个的步长是 1， 每一次滑动 1 个像素，而右边的步长是 2，会发现每一次滑动 2个像素。</li>
</ul>
<p><img src="/src/640-16464011129895-165691976075031.gif" alt="图片"></p>
<ul>
<li>padding: 填充个数，通常用来保持输入和输出图像的一个尺寸的匹配，依然是一个动图展示，看左边那个图，这个是没有 padding 的卷积，输入图像是 4 * 4，经过卷积之后，输出图像就变成了 2 * 2 的了，这样分辨率会遍变低，并且我们会发现这种情况卷积的时候边缘部分的像素参与计算的机会比较少。所以加入考虑 padding 的填充方式，这个也比较简单，就是在原输入周围加入像素，这样就可以保证输出的图像尺寸分辨率和输入的一样，并且边缘部分的像素也受到同等的关注了。</li>
</ul>
<p><img src="/src/640-16464011129896-165691976230334.gif" alt="图片"></p>
<ul>
<li><p>dilation: 孔洞卷积大小，下面依然是一个动图：</p>
<p><img src="/src/640-16464011129897-165691976455037.gif" alt="图片"></p>
<p>孔洞卷积就可以理解成一个带孔的卷积核，常用于图像分割任务，主要功能就是提高感受野。也就是输出图像的一个参数，能看到前面图像更大的一个区域。</p>
</li>
<li><p>groups: 分组卷积设置，分组卷积常用于模型的轻量化。我们之前的 AlexNet 其实就可以看到分组的身影， 两组卷积分别进行提取，最后合并。<img src="/src/640-16464011129898-165691976638840.png" alt="图片"></p>
</li>
<li><p>bias: 偏置</p>
</li>
</ul>
<p>下面是尺寸计算的方式：</p>
<ol>
<li>没有 padding：</li>
<li>如果有 padding 的话：</li>
<li>如果再加上孔洞卷积的话：</li>
</ol>
<p>下面我们用代码看看卷积核是怎么提取特征的，毕竟有图才有真相：</p>
<p><img src="/src/640-16464011129909-165691977038443.png" alt="图片"></p>
<p>接下来，我们改变seed， 也就是相当于换一组卷积核， 看看提取到什么样的特征：</p>
<p><img src="/src/640-164640111299010-165691977227646.png" alt="图片"></p>
<p>再换一个随机种子：</p>
<p><img src="/src/640-164640111299011-165691977391849.png" alt="图片"></p>
<p>通过上面，我们会发现不同权重的卷积核代表不同的模式，会关注不同的特征，这样我们只要设置多个卷积核同时对图片的特征进行提取，就可以提取不同的特征。</p>
<p>下面我们看一下图像尺寸的变化：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">卷积前尺寸:torch<span class="hljs-selector-class">.Size</span>(<span class="hljs-selector-attr">[1, 3, 512, 512]</span>)<br>卷积后尺寸:torch<span class="hljs-selector-class">.Size</span>(<span class="hljs-selector-attr">[1, 1, 510, 510]</span>)<br></code></pre></td></tr></table></figure>

<p>卷积前，图像尺寸是 , 卷积后，图像尺寸是 。我们这里的卷积核设置，输入通道 3，卷积核个数 1，卷积核大小 3，无 padding，步长是 1，那么我们根据上面的公式，输出尺寸:</p>
<p>下面再来看一下卷积层有哪些参数：我们知道卷积层也是继承于 nn.Module 的，所以肯定又是那 8 个字典属性， 我们主要看看它的<code>_modules</code>参数和<code>_parameters</code>参数字典。</p>
<p><img src="F:\notes\深度学习\src\640-164640111299012.png" alt="图片"></p>
<p>我们可以看到 Conv2d 下面的<code>_parameters</code>存放着权重参数，这里的 weight 的形状是 [1, 3, 3, 3]， 这个应该怎么理解呢？首先 1 代表着卷积核的个数，第 1 个 3 表示的输入通道数，后面两个 3 是二维卷积核的尺寸。那么这里有人可能会有疑问，我们这里是3维的卷积核啊，怎么实现的二维卷积呢？下面再通过一个示意图看看：</p>
<p><img src="F:\notes\深度学习\src\640-164640111299013.gif" alt="图片"></p>
<p>我们的图像是 RGB 3 个通道的图像，我们创建 3 个二维的卷积核，这 3 个二维的卷积核分别对应一个通道进行卷积，比如红色通道上，只有一个卷积核在上面滑动，每一次滑动，对应元素相乘然后相加得到一个数， 这三个卷积核滑动一次就会得到三个数，这三个数之和加上偏置才是我们的一个输出结果。这里我们看到了，一个卷积核只在 2 个维度上滑动，所以最后得到的就是 2 维卷积。这也能理解开始的卷积维度的概念了（一般情况下，卷积核在几个维度上滑动，就是几维卷积），为什么最后会得到的 3 维的张量呢？这是因为我们不止这一个卷积核啊，我们有多个卷积核的时候，每个卷积核都产生一个二维的结果，那么最后的输出不就成 3 维的了，第三个维度就是卷积核的个数了。下面用一个网站上的神图来看一下多个卷积核的提取特征，下面每一块扫描都是对应元素相乘再相加得到最后的的结果：</p>
<p><img src="/src/640-164640111299014-165691977665652.gif" alt="图片"></p>
<p>上面这一个是一个三维的卷积示意，并且使用了 2 个卷积核。最后会得到 2 个二维的张量。</p>
<p>二维卷积差不多说到这里吧，不明白我也没招了，我这已经浑身解数了，看这些动图也能看到吧，哈哈。毕竟这里主要讲 Pytorch，关于这些深度学习的基础这里不做过多的描述。下面再介绍一个转置卷积，看看这又是个啥？</p>
<h2 id="1-3-转置卷积"><a href="#1-3-转置卷积" class="headerlink" title="1.3 转置卷积"></a>1.3 转置卷积</h2><p>转置卷积又称为反卷积和部分跨越卷积（当然转置卷积这个名字比逆卷积要好，原因在下面），用于对图像进行上采样。在图像分割任务中经常被使用。首先为什么它叫转置卷积呢？</p>
<p>在解释这个之前，我们得先来看看正常的卷积在代码实现过程中的一个具体操作：对于正常的卷积，我们需要实现大量的相乘相加操作，而这种乘加的方式恰好是矩阵乘法所擅长的。所以在代码实现的时候，通常会借助矩阵乘法快速的实现卷积操作， 那么这是怎么做的呢？</p>
<p>我们假设图像尺寸为 , 卷积核为 , padding&#x3D;0, stride&#x3D;1，也就是下面这个图：</p>
<p><img src="/src/640-164640111299015-165691978158855.gif" alt="图片"></p>
<p>首先将图像尺寸的 拉长成 ，16 代表所有的像素，1 代表只有 1 张图片。然后 的卷积核会变成一个 的一个矩阵，一脸懵逼了，这是怎么变的，首先这个 16，是先把 9 个权值拉成一列，然后下面补 7 个 0 变成16， 这个 4 是根据我们输出的尺寸计算的，根据输入尺寸，卷积核大小，padding， stride 信息可以得到输出尺寸是 ， 所以输出是 ，那么拉成一列就是 4。这样我们的输出：</p>
<p>这样就得到了最后一列输出 4 个元素，然后 reshape 就得到了 的一个输出特征图了。这就是用矩阵乘法输出一个二维卷积的这样一个示例。这就是那个过程：</p>
<p><img src="/src/640-164640111299016-165691978313158.png" alt="图片"></p>
<p>下面我们看看转置卷积是怎么样的：</p>
<p>转置卷积是一个上采样，输入的图像尺寸是比较小的，经过转置卷积之后，会输出一个更大的图像，看下面示意图：</p>
<p><img src="/src/640-164640111299117-165691981478961.gif" alt="图片"></p>
<p>我们这里的输入图像尺寸是 ， 卷积核为 ， padding&#x3D;0， stride&#x3D;1, 我们的输入图像尺寸是 ，我们看看这个在代码中是怎么通过矩阵乘法进行实现的。首先，依然是把输入的尺寸进行拉长，成一个 的一个向量，然后我们的卷积核会变成 的，注意这里的卷积核尺寸，这个 4 依然是根据卷积核得来的，记得上面的那个 16 吗？我们是把卷积核拉长然后补 0， 在这里我们不是补 0 了，而是采用剔除的方法，因为我们根据上面的图像可以发现，虽然这里的卷积核有 9 个权值，可是能与图像相乘的最多只有四个（也就是卷积核在中间的时候），所以这里采用剔除的方法，从 9 个权值里面剔除 5 个，得到 4 个权重， 而这个 16，依然是根据输出图像的尺寸计算得来的。因为我们这里的输出是 ， 这个可以用上面尺寸运算的逆公式。所以这里的输出：</p>
<p>这次注意这个卷积核的尺寸是 ，而我们正常卷积运算的卷积核尺寸 ，所以在形状上这两个卷积操作卷积核恰恰是转置的关系，这也就是转置卷积的由来了。这是因为卷积核在转变成矩阵的时候，与正常卷积的卷积核形状上是互为转置，注意是形状，具体数值肯定是不一样的。所以正常卷积核转置卷积的关系并不是可逆的，故逆卷积这个名字不好。下面就具体学习 Pytorch 提供的转置卷积的方法：</p>
<p><code>nn.ConvTranspose2d</code>: 转置卷积实现上采样</p>
<p><img src="/src/640-164640111299118-165691981878464.png" alt="图片"></p>
<p>这个参数和卷积运算的参数差不多，就不再解释一遍了。</p>
<p>下面看看转置卷积的尺寸计算（卷积运算的尺寸逆）：</p>
<ol>
<li>无 padding：</li>
<li>有 padding：</li>
<li>有 padding 和孔洞卷积：</li>
</ol>
<p>下面从代码中看看转置卷积怎么用：</p>
<p><img src="/src/640-164640111299119-165691982268167.png" alt="图片"></p>
<p>转置卷积有个通病叫做“棋盘效应”，看上面图，这是由于不均匀重叠导致的。至于如何解决，这里就不多说了。</p>
<p>关于尺寸变化：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">卷积前尺寸:torch<span class="hljs-selector-class">.Size</span>(<span class="hljs-selector-attr">[1, 3, 512, 512]</span>)<br>卷积后尺寸:torch<span class="hljs-selector-class">.Size</span>(<span class="hljs-selector-attr">[1, 1, 1025, 1025]</span>)<br></code></pre></td></tr></table></figure>

<p>我们发现，输入图像是 512 的，卷积核大小是 3，stride&#x3D;2， 所以输出尺寸：</p>
<p>简单梳理，卷积部分主要是卷积运算，卷积尺寸的计算，然后又学习了转置卷积。下面我们看看 nn 中其他常用的层。</p>
<h1 id="2-池化层"><a href="#2-池化层" class="headerlink" title="2.池化层"></a>2.池化层</h1><p>池化运算：对信号进行“<strong>「收集」</strong>”并“<strong>「总结」</strong>”， 类似水池收集水资源， 因而美其名曰池化层。</p>
<ul>
<li>收集：多变少，图像的尺寸由大变小</li>
<li>总结：最大值&#x2F;平均值</li>
</ul>
<p>下面是一个最大池化的动态图看一下（平均池化就是这些元素去平均值作为最终值）：</p>
<p><img src="/src/640-164640111299120-165691982723470.gif" alt="图片"></p>
<p>最大池化就是这些元素里面去最大的值作为最终的结果。</p>
<p>下面看看 Pytorch 提供的最大池化和平均池化的函数：</p>
<p>nn.MaxPool2d: 对二维信号(图像）进行最大值池化。</p>
<p><img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299121.png" alt="图片"></p>
<ul>
<li>kernel_size: 池化核尺寸</li>
<li>stride: 步长</li>
<li>padding: 填充个数</li>
<li>dilation: 池化核间隔大小</li>
<li>ceil_mode: 尺寸向上取整</li>
<li>return_indices: 记录池化像素索引</li>
</ul>
<p>前四个参数和卷积的其实类似，最后一个参数常在最大值反池化的时候使用，那什么叫最大值反池化呢？看下图：</p>
<p><img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299122.png" alt="图片"></p>
<p>反池化就是将尺寸较小的图片通过上采样得到尺寸较大的图片，看右边那个，那是这些元素放到什么位置呢？ 这时候就需要当时最大值池化记录的索引了。用来记录最大值池化时候元素的位置，然后在最大值反池化的时候把元素放回去。</p>
<p>下面看一下最大池化的效果：</p>
<p><img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299123.png" alt="图片"></p>
<p>可以发现，图像基本上看不出什么差别，但是图像的尺寸减少了一半， 所以池化层是可以帮助我们剔除一些冗余像素的。</p>
<p>除了最大池化，还有一个叫做平均池化：</p>
<p>nn.AvgPool2d: 对二维信号(图像)进行平均值池化</p>
<p><img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299124.png" alt="图片"></p>
<ul>
<li>count_include_pad: 填充值用于计算</li>
<li>divisor_override: 除法因子， 这个是求平均的时候那个分母，默认是有几个数相加就除以几，当然也可以自己通过这个参数设定</li>
</ul>
<p>下面也是通过代码看一下结果：</p>
<p><img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299125.png" alt="图片">代码</p>
<p>这个平均池化和最大池化在这上面好像看不出区别来，其实最大池化的亮度会稍微亮一些，毕竟它都是取的最大值，而平均池化是取平均值。</p>
<p>好了，这就是池化操作了，下面再整理一个反池化操作，就是上面提到的 nn.MaxUnpool2d: 这个的功能是对二维信号(图像)进行最大池化上采样</p>
<p><img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299126.png" alt="图片"></p>
<p>这里的参数与池化层是类似的。唯一的不同就是前向传播的时候我们需要传进一个 indices， 我们的索引值，要不然不知道把输入的元素放在输出的哪个位置上呀，就像上面的那张图片：</p>
<p><img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299127.png" alt="图片"></p>
<p>下面通过代码来看一下反池化操作：</p>
<p><img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299228.png" alt="图片"></p>
<h1 id="3-线性层"><a href="#3-线性层" class="headerlink" title="3.线性层"></a>3.线性层</h1><p>线性层又称为全连接层，其每个神经元与上一层所有神经元相连实现对前一层的<strong>「线性组合，线性变换」</strong></p>
<p>线性层的具体计算过程在这里不再赘述，直接学习 Pytorch 的线性模块。</p>
<p><code>nn.Linear(in_features, out_features, bias=True)</code> : 对一维信号（向量）进行线性组合</p>
<ul>
<li>in_features: 输入节点数</li>
<li>out_features: 输出节点数</li>
<li>bias: 是否需要偏置</li>
</ul>
<p>计算公式：</p>
<p><img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299229.png" alt="图片"></p>
<p>下面可以看代码实现：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stylus">inputs = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1., 2, 3]</span>])<br>linear_layer = nn<span class="hljs-selector-class">.Linear</span>(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>)<br>linear_layer<span class="hljs-selector-class">.weight</span><span class="hljs-selector-class">.data</span> = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[[1., 1., 1.]</span>,<br>                                             <span class="hljs-selector-attr">[2., 2., 2.]</span>,<br>                                             <span class="hljs-selector-attr">[3., 3., 3.]</span>,<br>                                             <span class="hljs-selector-attr">[4., 4., 4.]</span>])<br><br>linear_layer<span class="hljs-selector-class">.bias</span><span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.fill_</span>(<span class="hljs-number">0.5</span>)<br>output = <span class="hljs-built_in">linear_layer</span>(inputs)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(inputs, inputs.shape)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(linear_layer.weight.data, linear_layer.weight.data.shape)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(output, output.shape)</span></span><br></code></pre></td></tr></table></figure>

<p>这个就比较简单了，不多说。</p>
<h1 id="4-激活函数层"><a href="#4-激活函数层" class="headerlink" title="4.激活函数层"></a>4.激活函数层</h1><p>激活函数 Udine 特征进行非线性变换， 赋予多层神经网络具有<strong>「深度」</strong>的意义。</p>
<p>如果没有激活函数，我们可以看一下下面的计算：</p>
<p><img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299230.png" alt="图片"></p>
<p>我们如果没有激活函数， 那么:</p>
<p>这里就可以看到，一个三层的全连接层，其实和一个线性层一样。这是因为我们线性运算的矩阵乘法的结合性，无论多少个线性层的叠加，其实就是矩阵的一个连乘，最后还是一个矩阵。所以如果没有激活函数，再深的网络也没有啥意义。</p>
<p>下面介绍几个常用的非线性激活函数：</p>
<ol>
<li>sigmoid 函数<img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299231.png" alt="图片"></li>
<li>nn.tanh<img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299232.png" alt="图片"></li>
<li>nn.ReLU<img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299233.png" alt="图片">ReLU 相对于前面的两个，效果要好一些， 因为不容易造成梯度消失，但是依然存在问题，所以下面就是对ReLU 进行的改进。<img src="https://gitee.com/xiang976young/note/raw/master/img/640-164640111299234.png" alt="图片"></li>
</ol>
<h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h1><p>这篇文章的内容到这里就差不多了，这次以基础的内容为主，简单的梳理一下，首先我们上次知道了构建神经网络的两个步骤：<strong>搭建子模块和拼接子模块。</strong>而这次就是学习各个子模块的使用。从比较重要的卷积层开始，学习了1d 2d 3d 卷积到底在干什么事情，采用了动图的方式进行演示，卷积运算其实就是通过不同的卷积核去提取不同的特征。然后学习了 Pytorch 的二维卷积运算及转置卷积运算，并进行了对比和分析了代码上如何实现卷积操作。</p>
<p>第二块是池化运算和池化层的学习，关于池化，一般和卷积一块使用，目的是收集和合并卷积提取的特征，去除一些冗余，分为最大池化和平均池化。然后学习了全连接层，这个比较简单，不用多说，最后是非线性激活函数，比较常用的 sigmoid，tanh, relu等。</p>
<p>今天的内容就到这里，模型模块基本上到这里也差不多了，根据我们的那个步骤：数据模块 -&gt; 模型模块 -&gt; 损失函数 -&gt; 优化器 -&gt; 迭代训练。所以下一次开始学习损失函数模块，但是在学习损失函数之前，还得先看一下常用的权重初始化方法，这个对于模型来说也是非常重要的。��模型来说也是非常重要的。</p>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Deep-Learning/" class="category-chain-item">Deep Learning</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Deep-Learning/">#Deep Learning</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Deep Learning—Layer说明</div>
      <div>http://example.com/2022/07/01/DeepLearning/各个层的解释/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Chris·Yougn</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年7月1日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/07/01/DeepLearning/%E4%BC%98%E5%8C%96%E5%99%A8/" title="Deep Learning—Optimizer">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Deep Learning—Optimizer</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/07/01/DeepLearning/%E5%AE%89%E8%A3%85pytorch/" title="Deep Learning——安装深度学习环境 torch、pyg">
                        <span class="hidden-mobile">Deep Learning——安装深度学习环境 torch、pyg</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments">
    
  <div id="waline"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#waline', function() {
      Fluid.utils.createCssLink('https://lib.baomitu.com/waline/2.5.1/waline.min.css')
      Fluid.utils.createScript('https://lib.baomitu.com/waline/2.5.1/waline.min.js', function() {
        var options = Object.assign(
          {"serverURL":"https://blog-comment-1abd33uwz-xiang64young.vercel.app","path":"window.location.pathname","meta":["nick","mail","link"],"requiredMeta":["nick"],"lang":"zh-CN","emoji":["https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo"],"dark":"html[data-user-color-scheme=\"dark\"]","wordLimit":0,"pageSize":10},
          {
            el: '#waline',
            path: window.location.pathname
          }
        )
        Waline.init(options);
        Fluid.utils.waitElementVisible('#waline .vcontent', () => {
          var imgSelector = '#waline .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});
  });
</script>





    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  

  

  

  

  

  

  







  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        MathJax = {
          tex    : {
            inlineMath: { '[+]': [['$', '$']] }
          },
          loader : {
            
          },
          options: {
            renderActions: {
              findScript    : [10, doc => {
                document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                  const display = !!node.type.match(/; *mode=display/);
                  const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                  const text = document.createTextNode('');
                  node.parentNode.replaceChild(text, node);
                  math.start = { node: text, delim: '', n: 0 };
                  math.end = { node: text, delim: '', n: 0 };
                  doc.math.push(math);
                });
              }, '', false],
              insertedScript: [200, () => {
                document.querySelectorAll('mjx-container').forEach(node => {
                  let target = node.parentNode;
                  if (target.nodeName.toLowerCase() === 'li') {
                    target.parentNode.classList.add('has-jax');
                  }
                });
              }, '', false]
            }
          }
        };
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
